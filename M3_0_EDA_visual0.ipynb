{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python para data science na prática\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise exploratória de dados (EDA)\n",
    "\n",
    "A análise exploratória de dados (EDA) é uma etapa crucial no processo de análise de dados, que envolve explorar e entender a natureza dos dados antes de aplicar qualquer modelo estatístico ou algoritmo de machine learning. \n",
    "\n",
    "A linguagem Python, junto da biblioteca Pandas, oferece uma ampla gama de ferramentas poderosas para realizar EDA de forma eficiente e eficaz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando dados para EDA \n",
    "\n",
    "Antes de analisar dados em tabelas ou dataframes, é fundamental preparar esses dados para garantir resultados precisos. Essa preparação pode incluir a transformação, agregação ou limpeza dos dados. Não existe uma abordagem única para todas as situações; as etapas de preparação dependem da estrutura específica dos nossos dados, como linhas, colunas, tipos e valores de dados. \n",
    "\n",
    "Algumas técnicas comuns de preparação de dados necessárias para EDA são: \n",
    "- Agrupamento de dados \n",
    "- Anexação de dados \n",
    "- Concatenação de dados \n",
    "- Mesclagem de dados \n",
    "- Classificação de dados \n",
    "- Categorização de dados \n",
    "- Remoção de dados duplicados \n",
    "- Eliminação de linhas e colunas de dados \n",
    "- Substituição de dados dados\n",
    "- Alterar um formato de dados\n",
    "- Lidar com valores ausentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrupamento de dados\n",
    "\n",
    "Agrupar dados implica agregar informações por categorias, o que é especialmente útil para obter uma visão geral de um conjunto de dados detalhado. \n",
    "\n",
    "Para realizar essa operação, geralmente identificamos a coluna ou categoria pela qual queremos agrupar, a coluna que queremos agregar e o tipo específico de agregação a ser aplicado. Normalmente, a coluna de agrupamento é categórica, enquanto a coluna a ser agregada é numérica. \n",
    "\n",
    "As agregações podem incluir contagem, soma, mínimo, máximo, entre outras. Também é possível realizar agregações diretamente na coluna categórica usada para o agrupamento, como contar os valores presentes.\n",
    "\n",
    "No `pandas`, o método para agrupar dados é `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo de agrupação de dados\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empregado = pd.read_csv('data/employees.csv', sep=',')\n",
    "df_empregado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizar só colunas com dados relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra dos nomes das colunas\n",
    "df_empregado.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados_relavantes = df_empregado[['First Name','Gender','Salary']]\n",
    "df_dados_relavantes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usar transpota para mostrar informação\n",
    "df_dados_relavantes.head(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando o método `groupby` em pandas para obter o número médio do salario dos empregados de uma loja com base no género dos empregados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrupos por salario\n",
    "agrupados_salario = df_dados_relavantes.groupby('Gender')['Salary'].mean()\n",
    "agrupados_salario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anexação de dados\n",
    "\n",
    "Às vezes, precisamos analisar múltiplos datasets com estruturas semelhantes ou amostras do mesmo dataset. Nesse processo, pode ser necessário juntar esses conjuntos em um único dataset. Ao anexar datasets, os unimos ao longo das linhas.\n",
    " \n",
    "Por exemplo, se temos dois conjuntos com 2.000 linhas e 30 colunas cada, o conjunto resultante terá 4.000 linhas e 30 colunas. Normalmente, as linhas aumentam, enquanto as colunas permanecem constantes. Embora os conjuntos de dados possam ter um número diferente de linhas, geralmente devem ter o mesmo número de colunas para evitar erros na anexação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em `pandas`, o método `concat` ajuda a acrescentar dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leitura dos dataset\n",
    "wine1 = pd.read_excel('data/Wine1.xlsx')\n",
    "print(wine1.shape)\n",
    "wine2 = pd.read_excel('data/Wine2.xlsx')\n",
    "print(wine2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifica os tipos\n",
    "print(wine1.dtypes)\n",
    "print('------')\n",
    "print(wine2.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anexando (Append datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append wine1 + wine2\n",
    "appende_wine = pd.concat([wine1,wine2])\n",
    "appende_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrando as dimensões\n",
    "print(appende_wine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver as informações da transposta\n",
    "appende_wine.head(4).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenação de dados\n",
    "\n",
    "Às vezes, é necessário unir vários conjuntos de dados ou amostras do mesmo dataset por colunas, em vez de por linhas. Nesse caso, realizamos a concatenação dos dados. Enquanto anexar dados adiciona linhas, concatenar colunas cria um único dataset. \n",
    "\n",
    "Por exemplo, se tivermos dois datasets, cada um com 5.000 linhas e 10 colunas, após a concatenação teremos 5.000 linhas e 20 colunas. \n",
    "\n",
    "Normalmente, as colunas aumentam, enquanto as linhas permanecem as mesmas. Os datasets podem ter diferentes números de colunas, mas geralmente devem ter o mesmo número de linhas para evitar erros após a concatenação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No `pandas`, o método `concat` nos ajuda a concatenar dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usaremos os dataset wine1 e wine2 usando no exemplo anterior\n",
    "# axis = 0 (linha) ou axis = 1 (coluna)\n",
    "concat_wine = pd.concat([wine1, wine2], axis = 1)\n",
    "concat_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra as dimensões\n",
    "concat_wine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver informações\n",
    "concat_wine.head(5).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mesclagem de dados\n",
    "\n",
    "Combinar dados pode se assemelhar à concatenação de datasets, mas é bem diferente. Para combinar datasets, é necessário um campo comum em ambos para realizar a junção. Se conhece alguns comandos SQL ou `join`, provavelmente já está familiarizado com o conceito de combinação de dados. Os dados de bancos de dados relacionais frequentemente exigem operações de junção, pois eles geralmente contêm dados tabulares e representam uma parte significativa dos dados em várias organizações.\n",
    "\n",
    "Alguns conceitos essenciais para operações de junção incluem:\n",
    "- `Coluna-chave de junção`: A coluna comum em ambos os datasets, onde há valores correspondentes. As colunas não precisam ter o mesmo nome, apenas valores correspondentes.\n",
    "- `Tipo de junção`: Existem diferentes tipos de junções que podem ser feitas em datasets:\n",
    "    - `Junção à esquerda`: Mantemos todas as linhas do dataframe à esquerda. Valores do dataframe à direita que não correspondem ao da esquerda são adicionados como `NaN` no resultado, com base na coluna-chave de junção.\n",
    "    - `Junção à direita`: Mantemos todas as linhas do dataframe à direita. Valores do dataframe à esquerda que não correspondem ao da direita são adicionados como `NaN` no resultado, com base na coluna-chave de junção.\n",
    "    - `Junção interna`: Retemos apenas os valores comuns em ambos os dataframes, sem valores `NaN`.\n",
    "    - `Junção externa completa`: Mantemos todas as linhas dos dataframes à esquerda e à direita. Valores não correspondentes são adicionados como `NaN` no resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Merge datasets](images/merge_datasets.png)\n",
    "Fonte: [Oluleye, 2023]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No `pandas`, o método `merge` é usado para mesclar dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando os datasets wine1 e wine2\n",
    "print('dataset1:',wine1.shape)\n",
    "print('dataset2:',wine2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mesclar os datasets `wine1` e `wine2`. Usar o método `merge` da biblioteca pandas para mesclar os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leitira dataset 3\n",
    "wine3 = pd.read_excel('data/Wine3.xlsx')\n",
    "print(wine3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge wine1 e wine2\n",
    "merge_wines = pd.merge(wine1,wine3,on='Alcohol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_wines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra as dimensões\n",
    "merge_wines.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar how = `inner`. Para ter uma interseção exata entre os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_inner = pd.merge(wine1, wine2, how ='inner', on = 'Alcohol')\n",
    "wine_inner.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_inner.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar how = `outer` para todas as informações, de ambos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "wine_outer = pd.merge(wine1,wine2, how = 'outer')\n",
    "wine_outer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimesões\n",
    "wine_outer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar how = `left` ou how= `right` depende de qual tabela se deixa na direita ou esquerda. \n",
    "\n",
    "Para o seguinte exemplo faremos um merge do tipo `left`. Mas o mesmo resultado pode ser obtido com um merge `right` trocando a posição das tabelas no método `merge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtém o mesmo resultado \n",
    "wine_left = pd.merge(wine2, wine1, how = 'left', on = 'Alcohol')\n",
    "print('left:',wine_left.shape)\n",
    "wine_right = pd.merge(wine1, wine2, how = 'right', on = 'Alcohol')\n",
    "print('right:',wine_right.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observação*: A chave usada para o merge sendo `Alcohol`, todas outras colunas iguais entre as tabelas são separadas em _x e _y, onde:\n",
    "- `_x` corresponde aos valores que existiam no dataset da esquerda (wine1).\n",
    "- `_y` Corresponde aos valores que existiam no dataset da direita (wine2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificação de dados\n",
    "\n",
    "Ao classificarmos dados, organizamos eles em uma ordem específica, o que facilita a identificação rápida de padrões. Para realizar a classificação de um conjunto de dados, precisamos definir uma ou mais colunas a serem usadas como base, além de especificar se a ordem será crescente ou decrescente. \n",
    "\n",
    "No pandas, o método `sort_values` ​​pode ser usado para classificar os elemntos de um dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando os nomes das colunas\n",
    "df_empregado.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting data- exemplo\n",
    "Empregado_sort = df_empregado.sort_values('Salary', ascending=False)\n",
    "Empregado_sort[['Gender','Salary']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorizando dados \n",
    "\n",
    "Ao nos referirmos à categorização de dados, estamos falando da divisão ou agrupamento de um conjunto de dados. A categorização consiste em organizar os valores numéricos em intervalos menores, chamados compartimentos. Quando fazemos isso, cada compartimento se torna um valor categórico. \n",
    "\n",
    "Os compartimentos são bastante úteis porque nos fornecem insights que seriam difíceis de detectar trabalhando com valores numéricos individuais. Os intervalos dos compartimentos não precisam ser iguais; a criação deles depende da nossa compreensão do conjunto de dados.\n",
    "\n",
    "O *binning* também pode ser usado para lidar com valores discrepantes ou reduzir o efeito de erros de observação. *Outliers* são pontos de dados extremamente altos ou baixos que se distanciam dos outros valores no datatset, muitas vezes causando anomalias na análise. A categorização pode mitigar esse efeito ao incluir esses valores discrepantes em intervalos específicos, tornando-os valores categóricos. \n",
    "\n",
    "Um exemplo comum é a conversão de idades em grupos etários. Idades atípicas, como `0` ou `150` anos, podem ser incluídas em categorias como menores de 18 anos e maiores de 80 anos, respectivamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No `pandas`, podemos usar o método `cut` para armazenar um dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escolhendo colunas relevantes\n",
    "empregado_cat = df_empregado[['First Name', 'Gender', 'Salary','Bonus %']]\n",
    "empregado_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mostrando dimensoes\n",
    "empregado_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorizamos o % do bonus em categorias zero, baixo, médio, alto, muito alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorizando\n",
    "pd.options.mode.copy_on_write = True \n",
    "#\n",
    "empregado_cat['bins'] = pd.cut(x=empregado_cat['Bonus %'],bins=[0,1,3,5,7,10], labels=\n",
    "                               ['zero','baixo','médio','alto','Muito alto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empregado_cat[['Bonus %','bins']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removendo dados duplicados \n",
    "\n",
    "Dados duplicados podem distorcer os resultados e nos levar a conclusões erradas sobre padrões e distribuição. Por isso, é crucial abordar a questão dos dados duplicados antes de iniciar qualquer análise. \n",
    "\n",
    "Realizar uma verificação rápida de duplicatas é uma boa prática na Análise Exploratória de Dados (EDA). \n",
    "\n",
    "Ao lidar com datasets tabulares, podemos identificar valores duplicados em colunas específicas ou registros duplicados em várias colunas. Compreender bem o dataset e o seu contexto ajuda a definir o que deve ser considerado duplicado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No `pandas`, o método `drop_duplicates` pode nos ajudar a lidar com valores ou registros duplicados nos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicatas\n",
    "empregado_dup = df_empregado[['First Name', 'Gender', 'Salary','Senior Management', 'Team']]\n",
    "empregado_dup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empregado_dup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover duplicatas\n",
    "empreado_duplicata = empregado_dup.drop_duplicates()\n",
    "empreado_duplicata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empreado_duplicata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Produtos =['iphone','iphone','ipad','aipod','Motorola','iphone']\n",
    "Precos = [1200,1300,500, 600,1000,1200]\n",
    "compras = pd.DataFrame({'produtos': Produtos, 'precos':Precos})\n",
    "compras.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "duplicates = compras.drop_duplicates()\n",
    "duplicates.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminando linhas e colunas de dados \n",
    "\n",
    "Ao lidar com dados tabulares, pode ser necessário remover algumas linhas ou colunas do dataset. Isso pode ocorrer quando as colunas ou linhas são incorretas ou irrelevantes. \n",
    "\n",
    "A biblioteca Pandas, tem a flexibilidade para eliminar uma única linha ou coluna, ou várias delas de uma vez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pode usar o método `drop` para eliminar linhas ou colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar \n",
    "compras.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar a linha 1\n",
    "drop_linha1 = compras.drop(labels=[1],axis=0)\n",
    "drop_linha1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrando colunas\n",
    "empreado_duplicata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar uma coluna\n",
    "drop_coluna = empreado_duplicata.drop(labels=['Senior Management'],axis=1)\n",
    "drop_coluna.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substituindo dados \n",
    "\n",
    "Trocar/substituir valores em linhas ou colunas é uma prática comum ao trabalhar com dados tabulares. Há várias razões pelas quais podemos precisar substituir valores específicos em um dataset. \n",
    "\n",
    "O Python tem a flexibilidade para substituir tanto valores únicos quanto múltiplos valores nos datasets.\n",
    "\n",
    "Podemos usar o método `replace` para substituir dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizar o dataset\n",
    "df_empregado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar as linhas e colunas em busca de anomalias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add coluna nula\n",
    "df_empregado['Married']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empregado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_empregado.replace('Douglas','Jorge')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Married']=df2['Married'].replace('0','S')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alterar um formato de dados \n",
    "\n",
    "Ao analisar ou explorar dados, o tipo de análise depende muito dos formatos ou tipos presentes no dataset. Geralmente, dados numéricos exigem técnicas analíticas específicas, enquanto dados categóricos precisam de abordagens diferentes. \n",
    "\n",
    "Portanto, é essencial que os tipos de dados sejam corretamente identificados antes do início da análise.\n",
    "\n",
    "No `pandas`, o atributo `dtypes` nos ajuda a inspecionar os tipos de dados em datasets, enquanto o atributo `astype` nos ajuda a converter os datasets entre vários tipos de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "df_data = df2[['First Name','Gender','Salary','Bonus %']]\n",
    "df_data['Married']='0'\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra os tipos antes\n",
    "df_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add linha zero\n",
    "df_data['Married'] = df_data['Married'].astype(int)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra os tipos depois\n",
    "df_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['Salary'] = df_data['Salary'].astype('Float64')\n",
    "df_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Python para data science na prática &copy; Jorge Zavaleta, 2024"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
